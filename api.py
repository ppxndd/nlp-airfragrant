from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import joblib
from pydantic import BaseModel
import pandas as pd
from pythainlp.corpus.common import thai_stopwords
from pythainlp import word_tokenize
from scipy.sparse import hstack


class Sentence(BaseModel):
    sentence: str


# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ
# model = joblib.load('rf_model.pkl')
# vectorizer = joblib.load('vectorizer.pkl')
# encoder = joblib.load('encoder.pkl')
thai_stopwords = list(thai_stopwords())
# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
model = joblib.load('model.pkl')
# ‡πÇ‡∏´‡∏•‡∏î vectorizer
vectorizer = joblib.load('vectorizer.pkl')
def my_tokenizer(text):
    return text.split(' ')
cvec = joblib.load('cvec.pkl')

# ‡πÇ‡∏´‡∏•‡∏î scaler
scaler = joblib.load('scaler.pkl')
# ‡πÇ‡∏´‡∏•‡∏î encoder_sentiment
encoder_sentiment = joblib.load('encoder_sentiment.pkl')
lr = joblib.load('lr.pkl')
# ‡πÇ‡∏´‡∏•‡∏î encoder
encoder = joblib.load('encoder.pkl')

def text_process(text):
    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", '"', "‡πÜ", "‡∏Ø"))
    final = word_tokenize(final)
    final = " ".join(word for word in final)
    final = " ".join(word for word in final.split() 
                     if word.lower not in thai_stopwords)
    return final
def getSentiment(my_text):
  my_tokens = text_process(my_text)
  my_bow = cvec.transform(pd.Series([my_tokens]))
  my_predictions = lr.predict(my_bow)
  return my_predictions[0]

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà URL ‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÑ‡∏î‡πâ
    allow_credentials=True,
    allow_methods=["*"],  # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏ó‡∏∏‡∏Å HTTP method (GET, POST, OPTIONS, etc.)
    allow_headers=["*"],  # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏ó‡∏∏‡∏Å headers
)

@app.get('/test')
def test():
    return {"result_message":"test"}

# @app.post("/predict_feeling")
# async def predict_feeling(sentence:Sentence):
#     text = [sentence.sentence]
#     X = vectorizer.transform(text)
#     prediction = model.predict(X)
#     predicted_label = encoder.inverse_transform(prediction)
#     feeling = None
#     if (predicted_label[0] == 'c'):
#         feeling = '‡∏ß‡∏≤‡∏ï‡∏∞'
#     elif (predicted_label[0] == 's'):
#         feeling = '‡πÄ‡∏™‡∏°‡∏´‡∏∞'
#     else:
#         feeling = '‡∏õ‡∏¥‡∏ï‡∏ï‡∏∞'
#     return {"result": feeling, "result_message": f"Prediction for '{text[0]}': {predicted_label[0]}"}

@app.post("/predict_feeling")
async def predict_feeling(sentence:Sentence):
    text = [sentence.sentence]
    new_sentence = "‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î"
    # üîπ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
    new_sentence_length = len(text)
    # üîπ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏î‡πâ‡∏ß‡∏¢ TF-IDF
    new_sentence_tfidf = vectorizer.transform([text])
    # üîπ ‡πÅ‡∏õ‡∏•‡∏á `sentence_length` ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Standardized Feature
    new_sentence_length_scaled = scaler.transform([[new_sentence_length]])
    #  üîπ ‡πÅ‡∏õ‡∏•‡∏á `sentiment` ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ (‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 'positive')
    new_sentence_sentiment = encoder_sentiment.transform([getSentiment(new_sentence)]).reshape(-1, 1)
    # üîπ ‡∏£‡∏ß‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á 3 (TF-IDF + sentence_length + sentiment)
    new_sentence_features = hstack((new_sentence_tfidf, new_sentence_length_scaled, new_sentence_sentiment))
    # üîπ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
    predicted_label = model.predict(new_sentence_features)

    # üîπ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    predicted_category = encoder.inverse_transform(predicted_label)
    return predicted_category[0]